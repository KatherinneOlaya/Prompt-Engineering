{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOWDo+sykC0769SHbBo9uj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KatherinneOlaya/Prompt-Engineering/blob/main/RAG_Chunk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HZ9nuFeoeLg",
        "outputId": "513a15a2-eff9-491d-fd0f-4c22a83f518a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/drive/MyDrive/Ai generative/attention-is-all-you-need-Paper.pdf\", \"doc.pdf\")\n",
        "print(\"PDF cargado!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO8ba5bnpXrG",
        "outputId": "d29644ad-f7ad-46d9-fb5d-a0a67c655b00"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF cargado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "FWz_zVDOp9Ts"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # ============= Extraer PDF =======================#\n",
        "\n",
        "from pypdf import PdfReader\n",
        "read = PdfReader(\"doc.pdf\")\n",
        "number_of_pages = len(read.pages)\n",
        "\n",
        "text =\"\"\n",
        "for page in read.pages:\n",
        "  text += page.extract_text()\n",
        "\n"
      ],
      "metadata": {
        "id": "WbkFNXk5p0yP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============= Chunks ===========================#\n",
        "\n",
        "def chunks(text, max_len = 300):\n",
        "  chunks_list = []\n",
        "  actual = []\n",
        "  words = text.split()\n",
        "\n",
        "  for word in words:\n",
        "    if len(\" \".join(actual)) + 1 + len(word) <= max_len:\n",
        "      actual.append(word)\n",
        "    else:\n",
        "      chunks_list.append(\" \".join(actual))\n",
        "      actual = [word]\n",
        "\n",
        "  if actual:\n",
        "    chunks_list.append(\" \".join(actual))\n",
        "\n",
        "  return chunks_list\n",
        "\n",
        "chunk = chunks(text)"
      ],
      "metadata": {
        "id": "WAZEJWzbutT0"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install groq\n"
      ],
      "metadata": {
        "id": "VnRrI_Q-xLmb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "client = Groq(api_key=\"\")\n"
      ],
      "metadata": {
        "id": "TeNEv0rzp85L"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#================= PROMPT ============================="
      ],
      "metadata": {
        "id": "ZtIJlU2dzPUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buscar(query):\n",
        "    relevantes = [c for c in chunk if query.lower() in c.lower()]\n",
        "    return relevantes[:5]  # Top 5"
      ],
      "metadata": {
        "id": "3IHf-25Izxb-"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag(question):\n",
        "  contextos = buscar(question)\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "    CONTEXTO:\n",
        "    {' '.join(contextos)}\n",
        "\n",
        "    PREGUNTA:\n",
        "    {question}\n",
        "\n",
        "    REGLAS:\n",
        "    - Responde únicamente usando el contexto.\n",
        "    - No inventes información.\n",
        "    \"\"\"\n",
        "  resp = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\":\"user\", \"content\": prompt}]\n",
        ")\n",
        "\n",
        "  return resp.choices[0].message.content"
      ],
      "metadata": {
        "id": "VVuygW6Tzppi"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag(\"Cual es la explicacion de Attention is all you need\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "0DJLlG8gy0FG",
        "outputId": "e1a02956-1b4a-4713-82e2-7b2ecc7f4016"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Attention is All You Need\" es un artículo de investigación publicado en 2017 por Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser y Polosukhin. En el artículo, los autores presentan una nueva arquitectura de modelo de lenguaje llamada Transformers (Transformadores).\\n\\nLa idea central del artículo es que tradicionalmente, los modelos de lenguaje utilizaban secuencialidad y se basaban en redes neuronales recurrentes (RNN) o redes neuronales convolucionales (CNN) para procesar secuencias de tokens. Sin embargo, estas arquitecturas no pueden manejar secuencias de longitud extensa de manera eficiente.\\n\\nLos autores proponen una nueva forma de atención llamada \"Attention is All You Need\", que utiliza una función de atención que permite al modelo considerar todas las posibles combinaciones de tokens en una secuencia al mismo tiempo. Esto permite al modelo capturar patrones y relaciones globales en la secuencia sin necesidad de recorrer la secuencia de manera secuencial.\\n\\nLa arquitectura Transformers utiliza una capa de atención autodireccional, que se puede aplicar en una secuencia de manera paralela, para calcular una representación de alto nivel de la secuencia. Esto permite al modelo realizar tareas como traducción máquina, clasificación de texto y generación de texto de manera más eficiente y precisa.\\n\\nEn resumen, la explicación de \"Attention is All You Need\" es una arquitectura de modelo de lenguaje llamada Transformers que utiliza una función de atención para procesar secuencias de tokens de manera paralela y capturar patrones y relaciones globales en la secuencia.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}